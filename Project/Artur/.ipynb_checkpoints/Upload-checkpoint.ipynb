{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (14, 8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "DATA_PATH = Path(\"__file__\").absolute().parent.parent / 'artur 2' / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv(DATA_PATH / 'data_cleaned.csv')\n",
    "df_old = df_old[['temperature', 'coluds_hight', 'snow', 'precipitation', 'pressure', 'date']]\n",
    "\n",
    "df_old['date'] = pd.to_datetime(df_old['date'], \n",
    "                            format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_old['month'] = pd.DatetimeIndex(df_old['date']).month\n",
    "df_old.index = df_old['date']\n",
    "df_old.drop(['date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv(DATA_PATH / 'data_cleaned_lol.csv')\n",
    "df_new = df_new[['temperature', 'coluds_hight', 'snow', 'precipitation', 'pressure', 'date']]\n",
    "\n",
    "df_new['date'] = pd.to_datetime(df_new['date'], \n",
    "                            format='%d.%m.%Y %H:%M')\n",
    "\n",
    "df_new['month'] = pd.DatetimeIndex(df_new['date']).month\n",
    "df_new.index = df_new['date']\n",
    "df_new.drop(['date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_old, df_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>coluds_hight</th>\n",
       "      <th>snow</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-10 17:00:00</th>\n",
       "      <td>13.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10 18:00:00</th>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>770.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10 19:00:00</th>\n",
       "      <td>12.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10 20:00:00</th>\n",
       "      <td>11.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10 21:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 19:00:00</th>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>761.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 20:00:00</th>\n",
       "      <td>5.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>762.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 21:00:00</th>\n",
       "      <td>4.7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>762.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 22:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 23:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>763.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65252 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temperature  coluds_hight  snow  precipitation  pressure  \\\n",
       "date                                                                            \n",
       "2013-07-10 17:00:00         13.6             8     0              0     771.7   \n",
       "2013-07-10 18:00:00         11.1             6     0              0     770.8   \n",
       "2013-07-10 19:00:00         12.9             8     0              0     771.5   \n",
       "2013-07-10 20:00:00         11.9             8     0              0     771.7   \n",
       "2013-07-10 21:00:00         10.0             1     0              0     771.3   \n",
       "...                          ...           ...   ...            ...       ...   \n",
       "2021-04-29 19:00:00          5.8             6     0              0     761.7   \n",
       "2021-04-29 20:00:00          5.9             6     0              0     762.1   \n",
       "2021-04-29 21:00:00          4.7             6     0              0     762.6   \n",
       "2021-04-29 22:00:00          4.0             8     0              0     763.0   \n",
       "2021-04-29 23:00:00          4.0             6     0              0     763.2   \n",
       "\n",
       "                     month  \n",
       "date                        \n",
       "2013-07-10 17:00:00      7  \n",
       "2013-07-10 18:00:00      7  \n",
       "2013-07-10 19:00:00      7  \n",
       "2013-07-10 20:00:00      7  \n",
       "2013-07-10 21:00:00      7  \n",
       "...                    ...  \n",
       "2021-04-29 19:00:00      4  \n",
       "2021-04-29 20:00:00      4  \n",
       "2021-04-29 21:00:00      4  \n",
       "2021-04-29 22:00:00      4  \n",
       "2021-04-29 23:00:00      4  \n",
       "\n",
       "[65252 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "cor = df.corr()\n",
    "cor_target = abs(cor[\"temperature\"])\n",
    "\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift the current temperature to the next day\n",
    "predicted_df = df[\"temperature\"].to_frame().shift(1).rename(columns={\"temperature\": \"T_mu_pred\"})\n",
    "actual_df = df[\"temperature\"].to_frame().rename(columns = {\"temperature\": \"T_mu_actual\"})\n",
    "\n",
    "#concatanate the actual and predicted temeprature \n",
    "one_step_df = pd.concat([actual_df,predicted_df],axis=1)\n",
    "\n",
    "#select from the second row, because no prediction for today because if the shifting\n",
    "one_step_df = one_step_df[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples of parameter combinations for seasonal ARIMA...\n",
      "SARIMAX: (0, 0, 1) x (0, 0, 1, 12)\n",
      "SARIMAX: (0, 0, 1) x (0, 1, 0, 12)\n",
      "SARIMAX: (0, 1, 0) x (0, 1, 1, 12)\n",
      "SARIMAX: (0, 1, 0) x (1, 0, 0, 12)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "#define the p, d and q parameters to take any value between 0 and 2\n",
    "p = d = q = range(0,2)\n",
    "\n",
    "#generate all different combinations p, d and q triplets\n",
    "pdq = list(itertools.product(p,d,q))\n",
    "\n",
    "#generate all different combinattion of seasonal p, d and q triplets \n",
    "seasonal_pdq = [(x[0],x[1],x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print(\"examples of parameter combinations for seasonal ARIMA...\")\n",
    "\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[1], seasonal_pdq[1]))\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[1], seasonal_pdq[2]))\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[2], seasonal_pdq[3]))\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "#import statsmodel for usibg SARIMA model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#fit the sarima model using optimal parameters \n",
    "mod = sm.tsa.statespace.SARIMAX(one_step_df.T_mu_actual,\n",
    "                                order=(1,1,1),\n",
    "                                seasonal_order=(1,0,1,12),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results.get_prediction(start=pd.to_datetime('2015-04-12'), dynamics=False)\n",
    "pred_ci = pred.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred.predicted_mean[-1]\n",
    "\n",
    "SAVE_TO = Path(\"__file__\").absolute().parent.parent / 'python'\n",
    "\n",
    "output_f = open('some_file.txt', \"w\")\n",
    "output_f.write(f\"{round(result, 1)}\")\n",
    "output_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "\n",
    "FTP_HOST = \"sandwichmelody.com\"\n",
    "FTP_USER = \"weather@sandwichmelody.com\"\n",
    "FTP_PASS = \"gJ5P4(Xw1)vw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the FTP server\n",
    "ftp = ftplib.FTP(FTP_HOST, FTP_USER, FTP_PASS)\n",
    "# force UTF-8 encoding\n",
    "ftp.encoding = \"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwx--x--x   60 sandwich   sandwich         4096 Apr 29 20:37 .\n",
      "drwx--x--x   60 sandwich   sandwich         4096 Apr 29 20:37 ..\n",
      "drwx--x--x    2 sandwich   sandwich           28 Feb  8  2020 .appdata\n",
      "-rw-r--r--    1 sandwich   sandwich           18 Jun 28  2019 .bash_logout\n",
      "-rw-r--r--    1 sandwich   sandwich          193 Jun 28  2019 .bash_profile\n",
      "-rw-r--r--    1 sandwich   sandwich          231 Jun 28  2019 .bashrc\n",
      "drwxrwx--x    5 sandwich   sandwich           55 May  8  2020 .cagefs\n",
      "drwxr-xr-x    2 sandwich   sandwich           90 Apr 22 03:22 .cl.selector\n",
      "-rw-r-----    1 sandwich   sandwich           21 Jun 28  2019 .contactemail\n",
      "drwx------    5 sandwich   sandwich          177 Apr 30 03:30 .cpanel\n",
      "drwx------    4 sandwich   sandwich           90 Jun 12  2020 .cphorde\n",
      "-rw-------    1 sandwich   sandwich           18 Apr 29 20:37 .ftpquota\n",
      "-rw-r--r--    1 sandwich   sandwich          139 May  8  2020 .gemrc\n",
      "drwxr-x---    2 sandwich   99                 10 Jun 28  2019 .htpasswds\n",
      "drwx------    2 sandwich   sandwich           32 Feb  8  2020 .kapps\n",
      "-rw-------    1 sandwich   sandwich          624 Apr 13 21:18 .lastlogin\n",
      "drwxr-----    3 sandwich   sandwich           27 Jun 28  2019 .pki\n",
      "drwx--x--x    7 sandwich   sandwich          227 Jun 11  2020 .softaculous\n",
      "drwx------    2 sandwich   sandwich           32 Jun 28  2019 .spamassassin\n",
      "-rw-r--r--    1 sandwich   sandwich            0 May  8  2020 .spamassassinboxenable\n",
      "-rw-r--r--    1 sandwich   sandwich            0 May  8  2020 .spamassassindisabled\n",
      "drwx------    2 sandwich   sandwich           10 Apr 21 11:10 .ssh\n",
      "drwx------    2 sandwich   sandwich           36 May  8  2020 .subaccounts\n",
      "drwx------    2 sandwich   sandwich           36 Apr 30 03:28 .trash\n",
      "drwxr-x---    8 sandwich   99                184 Mar 26 05:52 1905136.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 May 20  2020 360.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 May 12  2020 3chefs.sandwichmelody.com\n",
      "drwxr-x---    9 sandwich   99               4096 Apr 24 20:05 WinesForYou.sandwichmelody.com\n",
      "lrwxrwxrwx    1 sandwich   sandwich           34 May  8  2020 access-logs -> /etc/apache2/logs/domlogs/sandwich\n",
      "drwxr-xr-x    4 sandwich   sandwich           61 Mar  7 01:31 app\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 29 23:20 artur.sandwichmelody.com\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 29 05:20 beauty.sandwichmelody.com\n",
      "drwxr-x---    4 sandwich   99                 52 Jun  6  2020 booking.sandwichmelody.com\n",
      "drwxr-xr-x    2 sandwich   sandwich           10 May  8  2020 cache\n",
      "drwxr-x---    3 sandwich   99                 33 Jul  6  2020 canvasguy.sandwichmelody.com\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 30 00:22 cow.sandwichmelody.com\n",
      "-rw-r--r--    1 sandwich   sandwich            0 Feb  3  2020 cpbackup-exclude.conf\n",
      "drwxr-x---    9 sandwich   99               4096 Apr 24 17:08 data-viz.sandwichmelody.com\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 29 22:08 diaperstore.org\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 15 21:15 diaperstore.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 Jul  6  2020 dogos.sandwichmelody.com\n",
      "drwxr-x---    4 sandwich   12                109 Apr 29 20:37 etc\n",
      "drwxr-x---    3 sandwich   99                 33 May  9  2020 fabricshrinkage.sandwichmelody.com\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 29 05:49 front.sandwichmelody.com\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 30 02:22 glasses.sandwichmelody.com\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 29 13:53 go.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 Jul  6  2020 googlemap.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 Jun  4  2020 hotels.sandwichmelody.com\n",
      "drwxr-x---    7 sandwich   99               4096 Sep 18  2020 infacebeauty.co.uk\n",
      "drwxr-xr-x    3 sandwich   sandwich           29 Sep 18  2020 jakeovski.com\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 29 18:45 karina.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 May 16  2020 klava.sandwichmelody.com\n",
      "drwx------    2 sandwich   sandwich        45056 Apr 29 13:13 logs\n",
      "drwxrwx---   19 99         sandwich          253 Oct  4  2020 lscache\n",
      "drwxr-x--x    6 sandwich   sandwich         4096 Apr 29 19:23 mail\n",
      "drwxr-xr-x    2 sandwich   sandwich           10 Jun 17  2020 main_diaperstore.org\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 30 02:36 meat.sandwichmelody.com\n",
      "drwxr-xr-x    3 sandwich   sandwich           25 Mar  7 01:31 nodevenv\n",
      "drwxr-x---    3 sandwich   99                 33 May 10  2020 oxford.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   sandwich           30 Jun 28  2019 public_ftp\n",
      "drwxr-x---    9 sandwich   99               4096 Apr 30 00:07 public_html\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 30 01:43 rauf.sandwichmelody.com\n",
      "drwxr-x---    4 sandwich   99                155 Sep  9  2020 rgu.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 Jul  6  2020 saran.sandwichmelody.com\n",
      "drwxr-x---    3 sandwich   99                 33 May 12  2020 shoe.sandwichmelody.com\n",
      "drwx--x--x    3 sandwich   sandwich           25 Apr 23 20:43 softaculous_backups\n",
      "drwxr-xr-x    5 sandwich   sandwich          101 Apr 29 06:38 ssl\n",
      "-rw-r--r--    1 sandwich   sandwich          563 Dec  4  2019 test.json\n",
      "drwxr-x---    7 sandwich   99               4096 Apr 30 02:42 test.sandwichmelody.com\n",
      "drwxr-xr-x    7 sandwich   sandwich          183 Mar 26 06:04 tmp\n",
      "drwxr-xr-x    3 sandwich   sandwich           28 Jun 28  2019 var\n",
      "drwxr-x---    9 sandwich   99               4096 Apr 29 21:07 weather.sandwichmelody.com\n",
      "lrwxrwxrwx    1 sandwich   sandwich           11 Jun 28  2019 www -> public_html\n"
     ]
    }
   ],
   "source": [
    "# list current files & directories\n",
    "ftp.dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'250 OK. Current directory is /weather.sandwichmelody.com/wp-content/uploads'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp.cwd('/weather.sandwichmelody.com/wp-content/uploads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local file name you want to upload\n",
    "filename = \"some_file.txt\"\n",
    "with open(filename, \"rb\") as file:\n",
    "    # use FTP's STOR command to upload the file\n",
    "    ftp.storbinary(f\"STOR {filename}\", file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
